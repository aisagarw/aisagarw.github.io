<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Aishwarya Agarwal</title>
  <meta name="author" content="Aishwarya Agarwal">
  <meta property="og:url" content="http://aisagarw.me" />
  <meta property="og:title" content="Aishwarya Agarwal" />
  <meta property="og:image" content="http://aisagarw.me/img/Aishwarya.jpg" />

  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'EB Garamond', serif;
      background-color: #f9f9f9;
      color: #333;
    }

    .main-card {
      max-width: 1000px;
      margin: auto;
      margin-top: 60px;
      background-color: #fff;
      border-radius: 16px;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.05);
      overflow: hidden;
    }

    .card-img-top {
      object-fit: cover;
      height: 100%;
      border-bottom: 1px solid #eee;
    }

    .card-body {
      padding: 2rem;
    }

    h1, h2 {
      font-weight: bold;
    }

    h1 {
      font-size: 2.5rem;
    }

    a {
      color: #cb482c;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

.highlight-text {
  color: #cb482c; 
  font-weight: 800;
}

    .info-section p {
      margin-bottom: 0.75rem;
    }

    .publications ul {
      list-style-type: none;
      padding-left: 0;
    }

    .publications li {
      margin-bottom: 1.25rem;
    }

    footer {
      text-align: center;
      margin-top: 3rem;
      font-size: 0.9rem;
      color: #777;
    }

	  .timeline-date {
  font-weight: 500;
  font-family: 'EB Garamond', serif;
  color: #6c757d;
}



	  strong,
b {
  font-weight: 800 ;
  color: #000; /* Ensures solid black if text color is subdued */
}

	  .publications {
  font-family: 'EB Garamond', serif;
  color: #222;
}

.publications h2 {
  font-size: 2rem;
  border-bottom: 2px solid #ddd;
  padding-bottom: 0.5rem;
  margin-bottom: 1.5rem;
}

.publications h3, .publications h4 {
  font-weight: 600;
  margin-top: 2rem;
  color: #333;
}

.publications ul {
  list-style: none;
  padding-left: 0;
}

.publications li {
  margin-bottom: 1.5rem;
  line-height: 1.6;
  padding-left: 1.2rem;
  position: relative;
}

.publications li::before {
  content: '•';
  position: absolute;
  left: 0;
  top: 0.3rem;
  color: #666;
  font-size: 1rem;
}

.publications a {
  color: #0056b3;
  font-weight: 600;
  text-decoration: none;
}

.publications a:hover {
  text-decoration: underline;
}

.publications .conf {
  font-weight: bold;
  color: #000;
}

.publications .highlight {
  color: #C0392B;
  font-weight: 600;
}


	  

  </style>
</head>
<body>



  <div class="main-card">
  <div class="row align-items-center g-0 p-4">
  <div class="col-md-4 text-center mb-3 mb-md-0">
    <img src="img/Aishwarya2.jpg" 
         alt="Aishwarya Agarwal" 
         class="rounded-circle img-thumbnail shadow" 
         style="width: 250px; height: 250px; object-fit: cover;">
  </div>

  <div class="col-md-8">
    <div class="card-body ps-md-4 pe-md-3">
      <h1>Aishwarya Agarwal</h1>
      <p class="lead">Research Associate, Adobe | PhD (Part-time), IIIT Hyderabad</p>

      <p>
        I’m a Research Associate at <a href="https://research.adobe.com/" target="_blank">Adobe Research</a> India, and a part-time PhD student at CVIT, IIIT Hyderabad. 
        I'm advised by <a href="https://faculty.iiit.ac.in/~vgandhi/" target="_blank">Dr. Vineet Gandhi</a> and co-advised by 
        <a href="https://research.adobe.com/person/srikrishna-karanam/" target="_blank">Dr. Srikrishna Karanam</a>.
      </p>

      <p>
        My research focuses on Representation Learning in low-resource settings, Explainable Computer Vision, and customizing Diffusion Models 
        (e.g., Stable Diffusion) for creative tasks like text-to-image generation.
      </p>

      <p>
        I hold a Dual Degree (BTech + MTech) from <a href="https://www.iitb.ac.in/" target="_blank">IIT Bombay</a> in Electrical Engineering and AI & Data Science. 
        I previously interned at Adobe, working on multimodal understanding and scene enrichment.
      </p>

      <p class="mt-3"><strong>Email:</strong> agarwal.aishwarya2013@gmail.com</p>
      <p><strong>Links:</strong> 
        [<a href="files/Aishwarya_cvl.pdf" target="_blank">CV</a>] 
        [<a href="https://www.linkedin.com/in/aishwarya-agarwal-081a58181/" target="_blank">LinkedIn</a>]
      </p>
    </div>
  </div>
</div>

 <!-- News Section -->
<!-- News Section -->
<div class="container py-5">
  <h2 class="mb-4">News</h2>
  <ul class="list-unstyled">
    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">March 28, 2025</div>
      <div class="flex-grow-1">
        Our work on enabling disentangled color-style control in diffusion models got accepted in <b>CVPR CVEU Workshop 2025</b>!
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">Feb 27, 2025</div>
      <div class="flex-grow-1">
        Two papers accepted at <b>CVPR 2025</b>. Our paper <span class="highlight-text">TIDE</span> on training locally interpretable models is selected as a <span class="highlight-text">Highlight</span>! 
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">Oct 29, 2024</div>
      <div class="flex-grow-1">
        Two papers accepted at <b>WACV 2025</b> on training-free diffusion model customization while balancing <span class="highlight-text">reconstruction-editability tradeoff</span>.
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">Oct 23, 2023</div>
      <div class="flex-grow-1">
        Our iterative image editing work using diffusion models is accepted to <b>WACV 2024</b>.
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">Jul 14, 2023</div>
      <div class="flex-grow-1">
        Work on improving <span class="highlight-text">image-text alignment</span> in diffusion models accepted to <b>ICCV 2023</b>!
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">Mar 4, 2023</div>
      <div class="flex-grow-1">
        <i>Sketchbuddy</i>, our project on <span class="highlight-text">assisted sketching</span>, is accepted to <b>ACM MMSys 2023</b>. Part of my undergrad internship at Adobe!
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">Aug 26, 2022</div>
      <div class="flex-grow-1">
        Research on <span class="highlight-text">open-set cross-domain generalization</span> accepted to <b>WACV 2023</b> — part of my IITB thesis with Adobe.
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">Jul 12, 2022</div>
      <div class="flex-grow-1">
        Joined <span class="highlight-text">Adobe Research, Bangalore</span>!.
      </div>
    </li>

    <li class="mb-4 d-flex align-items-start">
      <div class="timeline-date pe-4" style="width: 140px;">June 24, 2022</div>
      <div class="flex-grow-1">
        Our work on <span class="highlight-text">few-shot class-incremental learning</span> accepted to <b>ACM Multimedia 2022</b>. My first lead-author paper with Prof. Biplab!
      </div>
    </li>
  </ul>
</div>



  

 <div class="container publications mt-5">
  <h2>Publications</h2>

  <h4>2025</h4>
  <ul>
    <li>
      <a href="https://arxiv.org/abs/2409.02429" target="_blank">
        Training-free Color-Style Disentanglement for Constrained Text-to-Image Synthesis
      </a><br/>
      In <span class="conf">Computer Vision and Pattern Recognition Workshop (CVPRW)</span>, 2025.
    </li>
    <li>
      <a href="https://arxiv.org/abs/2411.16788" target="_blank">
        TIDE: Training Locally Interpretable Domain Generalization Models Enables Test-time Correction
      </a><br/>
      In <span class="conf">Computer Vision and Pattern Recognition (CVPR)</span>, 2025 <span class="highlight">(Highlight)</span>.
    </li>
    <li>
      <a href="https://arxiv.org/abs/2406.10197" target="_blank">
        Composing Parts for Expressive Object Generation
      </a><br/>
      In <span class="conf">Computer Vision and Pattern Recognition (CVPR)</span>, 2025.
    </li>
    <li>
      <a href="https://arxiv.org/abs/2311.11919" target="_blank">
        An Image is Worth Multiple Words: Multi-attribute Inversion for Constrained Text-to-Image Synthesis
      </a><br/>
      In <span class="conf">Winter Conference on Applications of Computer Vision (WACV)</span>, 2025.
    </li>
    <li>
      <a href="https://arxiv.org/abs/2406.18893" target="_blank">
        AlignIT: Enhancing Prompt Alignment in Customization of Text-to-Image Models
      </a><br/>
      In <span class="conf">Winter Conference on Applications of Computer Vision (WACV)</span>, 2025.
    </li>
  </ul>

  <h4>2024</h4>
  <ul>
    <li>
      <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Joseph_Iterative_Multi-Granular_Image_Editing_Using_Diffusion_Models_WACV_2024_paper.pdf" target="_blank">
        Iterative Multi-Granular Image Editing Using Diffusion Models
      </a><br/>
      In <span class="conf">Winter Conference on Applications of Computer Vision (WACV)</span>, 2024.
    </li>
  </ul>

  <h4>2023</h4>
  <ul>
    <li>
      <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.pdf" target="_blank">
        ASTAR: Test-time Attention Segregation and Retention for Text-to-image Synthesis
      </a><br/>
      In <span class="conf">International Conference on Computer Vision (ICCV)</span>, 2023.
    </li>
    <li>
      <a href="https://dl.acm.org/doi/abs/10.1145/3587819.3590980" target="_blank">
        SketchBuddy: Context-Aware Sketch Enrichment and Enhancement
      </a><br/>
      In <span class="conf">ACM Multimedia Systems Conference (ACM MMSys)</span>, 2023.
    </li>
    <li>
      <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_Contrastive_Learning_of_Semantic_Concepts_for_Open-Set_Cross-Domain_Retrieval_WACV_2023_paper.pdf" target="_blank">
        Contrastive Learning of Semantic Concepts for Open-set Cross-domain Retrieval
      </a><br/>
      In <span class="conf">Winter Conference on Applications of Computer Vision (WACV)</span>, 2023.
    </li>
  </ul>

  <h4>2022</h4>
  <ul>
    <li>
      <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548160" target="_blank">
        Semantics-Driven Generative Replay for Few-Shot Class Incremental Learning
      </a><br/>
      In <span class="conf">ACM International Conference on Multimedia (ACM MM)</span>, 2022.
    </li>
  </ul>

  <h4>2021</h4>
  <ul>
    <li>
      <a href="https://aclanthology.org/2021.naacl-main.418/" target="_blank">
        MIMOQA: Multimodal Input Multimodal Output Question Answering
      </a><br/>
      In <span class="conf">North American Chapter of the Association for Computational Linguistics (NAACL-HLT)</span>, 2021.
    </li>
  </ul>
</div>


  <footer>
    &copy; 2025 Aishwarya Agarwal
  </footer>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
